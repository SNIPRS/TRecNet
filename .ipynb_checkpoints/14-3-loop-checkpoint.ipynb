{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Input, concatenate, Masking, LSTM, TimeDistributed, Lambda, Reshape, Multiply, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras import regularizers \n",
    "from tensorflow.keras import initializers\n",
    "import h5py \n",
    "import os \n",
    "from clr_callback import *\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow.keras.backend as K  \n",
    "from tensorflow.keras.optimizers import * \n",
    "import glob\n",
    "import re\n",
    "import importlib \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "# Required python scripts and files \n",
    "import normalize\n",
    "import shape_timesteps\n",
    "X_maxmean = np.load('saved/X_maxmean1.npy')\n",
    "Y_maxmean = np.load('saved/Y_maxmean1.npy')\n",
    "\n",
    "\n",
    "# Parameters\n",
    "# Path to h5 file\n",
    "name = './../../../../../data/hongtao/inputs_2021-02-05/variables_tt_rmu_padded.h5'\n",
    "\n",
    "\n",
    "\n",
    "name0 = os.path.basename(name)\n",
    "name0 = re.sub('\\.h5$', '', name0)\n",
    "dataset = h5py.File(name,'r')\n",
    "# ['j1_pt', 'j1_eta', 'j1_phi', 'j1_x', 'j1_y', 'j1_z', 'j1_m', 'j1_e', 'j1_DL1r', 'j1_isbtag', 'j2_pt', 'j2_eta', 'j2_phi', 'j2_x', 'j2_y', 'j2_z', 'j2_m', 'j2_e', 'j2_DL1r', 'j2_isbtag', 'j3_pt', 'j3_eta', 'j3_phi', 'j3_x', 'j3_y', 'j3_z', 'j3_m', 'j3_e', 'j3_DL1r', 'j3_isbtag', 'j4_pt', 'j4_eta', 'j4_phi', 'j4_x', 'j4_y', 'j4_z', 'j4_m', 'j4_e', 'j4_DL1r', 'j4_isbtag', 'j5_pt', 'j5_eta', 'j5_phi', 'j5_x', 'j5_y', 'j5_z', 'j5_m', 'j5_e', 'j5_DL1r', 'j5_isbtag', 'j6_pt', 'j6_eta', 'j6_phi', 'j6_x', 'j6_y', 'j6_z', 'j6_m', 'j6_e', 'j6_DL1r', 'j6_isbtag', 'lep_pt', 'lep_eta', 'lep_phi', 'lep_x', 'lep_y', 'lep_z', 'lep_e', 'met_met', 'met_phi']\n",
    "size = np.array(dataset.get('th_pt')).size\n",
    "X_keys = ['j1_pt', 'j1_eta', 'j1_phi', 'j1_m', 'j1_DL1r', 'j2_pt', 'j2_eta', 'j2_phi', 'j2_m', 'j2_DL1r', 'j3_pt', 'j3_eta', 'j3_phi', 'j3_m', 'j3_DL1r', 'j4_pt', 'j4_eta', 'j4_phi', 'j4_m', 'j4_DL1r', 'j5_pt', 'j5_eta', 'j5_phi', 'j5_m', 'j5_DL1r', 'j6_pt', 'j6_eta', 'j6_phi', 'j6_m', 'j6_DL1r', 'lep_pt', 'lep_eta', 'lep_phi', 'met_met', 'met_phi']\n",
    "Y_keys = ['th_pt', 'th_eta','th_phi','th_m', 'wh_pt', 'wh_eta', 'wh_phi', 'wh_m', 'tl_pt', 'tl_eta', 'tl_phi', 'tl_m', 'wl_pt', 'wl_eta', 'wl_phi', 'wl_m']\n",
    "\n",
    "phi_keys = list(filter(lambda a: 'phi' in a, dataset.keys()))\n",
    "eta_keys = list(filter(lambda a: 'eta' in a, dataset.keys()))\n",
    "pt_keys =  list(filter(lambda a: 'pt' in a, dataset.keys()))\n",
    "m_keys = list(filter(lambda a: 'm' in a, dataset.keys()))\n",
    "DL1r_keys = list(filter(lambda a: 'DL1r' in a, dataset.keys()))\n",
    "\n",
    "Y_length = len(Y_keys)\n",
    "X_length = len(X_keys)\n",
    "crop0 =  size\n",
    "print(name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "importlib.reload(normalize)\n",
    "importlib.reload(shape_timesteps)\n",
    "\n",
    "Scaler = normalize.Scale_variables()\n",
    "X_total, X_names = Scaler.scale_arrays(X_keys, X_maxmean)\n",
    "Y_total, Y_names = Scaler.scale_arrays(Y_keys, Y_maxmean)\n",
    "\n",
    "# print('Max scaling error: {}'.format(error))\n",
    "\n",
    "# Create X and test array\n",
    "split = int(np.floor(0.95*crop0)) \n",
    "split = 0 \n",
    "\n",
    "trainY, testY = Y_total[0:split,:], Y_total[split:,:]\n",
    "\n",
    "timestep_builder = shape_timesteps.Shape_timesteps()\n",
    "\n",
    "totalX_jets, totalX_other = timestep_builder.reshape_X(X_total, X_names, False,True)\n",
    "\n",
    "trainX_jets, testX_jets = totalX_jets[0:split,:,:], totalX_jets[split:,:,:]\n",
    "trainX_other, testX_other = totalX_other[0:split,:], totalX_other[split:,:]\n",
    "print(testX_jets.shape, testX_other.shape, testY.shape)\n",
    "\n",
    "if testX_jets.shape[0] > 0: \n",
    "    other_bins = np.linspace(-1, 1, 40)\n",
    "    phi_bins = np.linspace(-1, 1, 40)\n",
    "    pt_bins = np.linspace(-1, 1, 40)\n",
    "    Y_bins = [phi_bins if 'phi' in name else pt_bins if 'pt' in name else other_bins for name in Y_names]\n",
    "\n",
    "    model = keras.models.load_model('12-3-clean.keras', custom_objects={'loss_fc':loss_fc})\n",
    "\n",
    "    predictions_unscaled = model.predict([testX_jets, testX_other])\n",
    "    true_unscaled = testY \n",
    "\n",
    "    total_predictions = model.predict([np.append(trainX_jets,testX_jets,axis=0), np.append(trainX_other,testX_other,axis=0)])\n",
    "    Y_total, _ = Scaler.scale_arrays(Y_keys, Y_maxmean)\n",
    "\n",
    "    predictions_origscale = Scaler.invscale_arrays(total_predictions, Y_names, Y_maxmean)[split:,:]\n",
    "    true_origscale = Scaler.invscale_arrays(Y_total, Y_names, Y_maxmean)[split:,:]\n",
    "\n",
    "    np.save('saved/13-3-2021/'+name0+'', predictions_origscale)\n",
    "    np.save('saved/13-3-2021/'+name0+'-true', true_origscale)\n",
    "else:\n",
    "    print('skip')\n",
    "dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1750_re_padded.h5\n",
      "(5226, 6, 6) (5226, 7) (5226, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime5000_rmu_padded.h5\n",
      "(4343, 6, 6) (4343, 7) (4343, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime2250_re_padded.h5\n",
      "(3482, 6, 6) (3482, 7) (3482, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime2250_rmu_padded.h5\n",
      "(3910, 6, 6) (3910, 7) (3910, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime400_rmu_padded.h5\n",
      "(10146, 6, 6) (10146, 7) (10146, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1500_rmu_padded_padded.h5\n",
      "(7243, 6, 6) (7243, 7) (7243, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime2000_re_padded.h5\n",
      "(4256, 6, 6) (4256, 7) (4256, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_singletop_re_padded.h5\n",
      "(0, 6, 6) (0, 7) (0, 20)\n",
      "skip\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_singletop_rmu_padded.h5\n",
      "(0, 6, 6) (0, 7) (0, 20)\n",
      "skip\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime500_rmu_padded_padded.h5\n",
      "(11256, 6, 6) (11256, 7) (11256, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime750_rmu_padded_padded.h5\n",
      "(13853, 6, 6) (13853, 7) (13853, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1500_rmu_padded.h5\n",
      "(7243, 6, 6) (7243, 7) (7243, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zjets_rmu_padded.h5\n",
      "(0, 6, 6) (0, 7) (0, 20)\n",
      "skip\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime750_re_padded.h5\n",
      "(13203, 6, 6) (13203, 7) (13203, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zjets_re_padded.h5\n",
      "(0, 6, 6) (0, 7) (0, 20)\n",
      "skip\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime4000_re_padded.h5\n",
      "(2611, 6, 6) (2611, 7) (2611, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime3000_rmu_padded.h5\n",
      "(4205, 6, 6) (4205, 7) (4205, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime4000_rmu_padded.h5\n",
      "(2909, 6, 6) (2909, 7) (2909, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime750_rmu_padded.h5\n",
      "(13853, 6, 6) (13853, 7) (13853, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime400_re_padded.h5\n",
      "(8775, 6, 6) (8775, 7) (8775, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1250_re_padded.h5\n",
      "(8861, 6, 6) (8861, 7) (8861, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1750_rmu_padded.h5\n",
      "(5315, 6, 6) (5315, 7) (5315, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime2500_re_padded.h5\n",
      "(3018, 6, 6) (3018, 7) (3018, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime2000_rmu_padded.h5\n",
      "(4875, 6, 6) (4875, 7) (4875, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime500_rmu_padded.h5\n",
      "(11256, 6, 6) (11256, 7) (11256, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime2500_rmu_padded.h5\n",
      "(3420, 6, 6) (3420, 7) (3420, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_vv_re_padded.h5\n",
      "(0, 6, 6) (0, 7) (0, 20)\n",
      "skip\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_vv_rmu_padded.h5\n",
      "(0, 6, 6) (0, 7) (0, 20)\n",
      "skip\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime500_re_padded.h5\n",
      "(10385, 6, 6) (10385, 7) (10385, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_wjets_rmu_padded.h5\n",
      "(0, 6, 6) (0, 7) (0, 20)\n",
      "skip\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime5000_re_padded.h5\n",
      "(3978, 6, 6) (3978, 7) (3978, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1000_re_padded.h5\n",
      "(16887, 6, 6) (16887, 7) (16887, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime3000_re_padded.h5\n",
      "(3672, 6, 6) (3672, 7) (3672, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime2750_rmu_padded.h5\n",
      "(3202, 6, 6) (3202, 7) (3202, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime2750_re_padded.h5\n",
      "(2689, 6, 6) (2689, 7) (2689, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1500_re_padded.h5\n",
      "(6965, 6, 6) (6965, 7) (6965, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1250_rmu_padded.h5\n",
      "(9256, 6, 6) (9256, 7) (9256, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1000_rmu_padded.h5\n",
      "(17404, 6, 6) (17404, 7) (17404, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_wjets_re_padded.h5\n",
      "(0, 6, 6) (0, 7) (0, 20)\n",
      "skip\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Input, concatenate, Masking, LSTM, TimeDistributed, Lambda, Reshape, Multiply, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras import regularizers \n",
    "from tensorflow.keras import initializers\n",
    "import h5py \n",
    "import os \n",
    "from clr_callback import *\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow.keras.backend as K  \n",
    "from tensorflow.keras.optimizers import * \n",
    "import glob\n",
    "import re\n",
    "import importlib \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "names = glob.glob(\"./../../../../../data/hongtao/inputs_2021-02-05/*_padded.h5\")\n",
    "def loss_fc(true, pred):\n",
    "        return K.mean(K.square(true-pred)*(1+3*K.square(K.abs(true))))\n",
    "names.remove('./../../../../../data/hongtao/inputs_2021-02-05/variables_tt_rmu_padded.h5')\n",
    "names.remove('./../../../../../data/hongtao/inputs_2021-02-05/variables_tt_re_padded.h5')\n",
    "\n",
    "for name in names:\n",
    "    # name = re.sub('\\_padded.h5$', '', name)+'.h5'\n",
    "    name0 = os.path.basename(name)\n",
    "    name0 = re.sub('\\.h5$', '', name0)\n",
    "    dataset = h5py.File(name,'r')\n",
    "    # ['j1_pt', 'j1_eta', 'j1_phi', 'j1_x', 'j1_y', 'j1_z', 'j1_m', 'j1_e', 'j1_DL1r', 'j1_isbtag', 'j2_pt', 'j2_eta', 'j2_phi', 'j2_x', 'j2_y', 'j2_z', 'j2_m', 'j2_e', 'j2_DL1r', 'j2_isbtag', 'j3_pt', 'j3_eta', 'j3_phi', 'j3_x', 'j3_y', 'j3_z', 'j3_m', 'j3_e', 'j3_DL1r', 'j3_isbtag', 'j4_pt', 'j4_eta', 'j4_phi', 'j4_x', 'j4_y', 'j4_z', 'j4_m', 'j4_e', 'j4_DL1r', 'j4_isbtag', 'j5_pt', 'j5_eta', 'j5_phi', 'j5_x', 'j5_y', 'j5_z', 'j5_m', 'j5_e', 'j5_DL1r', 'j5_isbtag', 'j6_pt', 'j6_eta', 'j6_phi', 'j6_x', 'j6_y', 'j6_z', 'j6_m', 'j6_e', 'j6_DL1r', 'j6_isbtag', 'lep_pt', 'lep_eta', 'lep_phi', 'lep_x', 'lep_y', 'lep_z', 'lep_e', 'met_met', 'met_phi']\n",
    "    size = np.array(dataset.get('th_pt')).size\n",
    "    X_keys = ['j1_pt', 'j1_eta', 'j1_phi', 'j1_m', 'j1_DL1r', 'j2_pt', 'j2_eta', 'j2_phi', 'j2_m', 'j2_DL1r', 'j3_pt', 'j3_eta', 'j3_phi', 'j3_m', 'j3_DL1r', 'j4_pt', 'j4_eta', 'j4_phi', 'j4_m', 'j4_DL1r', 'j5_pt', 'j5_eta', 'j5_phi', 'j5_m', 'j5_DL1r', 'j6_pt', 'j6_eta', 'j6_phi', 'j6_m', 'j6_DL1r', 'lep_pt', 'lep_eta', 'lep_phi', 'met_met', 'met_phi']\n",
    "    Y_keys = ['th_pt', 'th_eta','th_phi','th_m', 'wh_pt', 'wh_eta', 'wh_phi', 'wh_m', 'tl_pt', 'tl_eta', 'tl_phi', 'tl_m', 'wl_pt', 'wl_eta', 'wl_phi', 'wl_m']\n",
    "\n",
    "    phi_keys = list(filter(lambda a: 'phi' in a, dataset.keys()))\n",
    "    eta_keys = list(filter(lambda a: 'eta' in a, dataset.keys()))\n",
    "    pt_keys =  list(filter(lambda a: 'pt' in a, dataset.keys()))\n",
    "    m_keys = list(filter(lambda a: 'm' in a, dataset.keys()))\n",
    "    DL1r_keys = list(filter(lambda a: 'DL1r' in a, dataset.keys()))\n",
    "\n",
    "    Y_length = len(Y_keys)\n",
    "    X_length = len(X_keys)\n",
    "    crop0 =  size\n",
    "    print(name)\n",
    "\n",
    "    X_maxmean = np.load('saved/X_maxmean1.npy')\n",
    "    Y_maxmean = np.load('saved/Y_maxmean1.npy')\n",
    "\n",
    "    import normalize\n",
    "    importlib.reload(normalize)\n",
    "    import shape_timesteps\n",
    "    importlib.reload(shape_timesteps)\n",
    "\n",
    "    Scaler = normalize.Scale_variables()\n",
    "    X_total, X_names = Scaler.scale_arrays(X_keys, X_maxmean)\n",
    "    Y_total, Y_names = Scaler.scale_arrays(Y_keys, Y_maxmean)\n",
    "\n",
    "    # print('Max scaling error: {}'.format(error))\n",
    "\n",
    "    # Create X and test array\n",
    "    split = int(np.floor(0.95*crop0)) \n",
    "    split = 0 \n",
    "\n",
    "    trainY, testY = Y_total[0:split,:], Y_total[split:,:]\n",
    "\n",
    "    timestep_builder = shape_timesteps.Shape_timesteps()\n",
    "\n",
    "    totalX_jets, totalX_other = timestep_builder.reshape_X(X_total, X_names, False,True)\n",
    "\n",
    "    trainX_jets, testX_jets = totalX_jets[0:split,:,:], totalX_jets[split:,:,:]\n",
    "    trainX_other, testX_other = totalX_other[0:split,:], totalX_other[split:,:]\n",
    "    print(testX_jets.shape, testX_other.shape, testY.shape)\n",
    "    \n",
    "    if testX_jets.shape[0] > 0: \n",
    "        other_bins = np.linspace(-1, 1, 40)\n",
    "        phi_bins = np.linspace(-1, 1, 40)\n",
    "        pt_bins = np.linspace(-1, 1, 40)\n",
    "        Y_bins = [phi_bins if 'phi' in name else pt_bins if 'pt' in name else other_bins for name in Y_names]\n",
    "\n",
    "        model = keras.models.load_model('12-3-clean.keras', custom_objects={'loss_fc':loss_fc})\n",
    "\n",
    "        predictions_unscaled = model.predict([testX_jets, testX_other])\n",
    "        true_unscaled = testY \n",
    "\n",
    "        total_predictions = model.predict([np.append(trainX_jets,testX_jets,axis=0), np.append(trainX_other,testX_other,axis=0)])\n",
    "        Y_total, _ = Scaler.scale_arrays(Y_keys, Y_maxmean)\n",
    "\n",
    "        predictions_origscale = Scaler.invscale_arrays(total_predictions, Y_names, Y_maxmean)[split:,:]\n",
    "        true_origscale = Scaler.invscale_arrays(Y_total, Y_names, Y_maxmean)[split:,:]\n",
    "\n",
    "        np.save('saved/13-3-2021/'+name0+'', predictions_origscale)\n",
    "        np.save('saved/13-3-2021/'+name0+'-true', true_origscale)\n",
    "    else:\n",
    "        print('skip')\n",
    "    dataset.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1750_re.h5\n",
      "(6613, 6, 6) (6613, 7) (6613, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime5000_rmu.h5\n",
      "(5247, 6, 6) (5247, 7) (5247, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime2250_re.h5\n",
      "(4478, 6, 6) (4478, 7) (4478, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime2250_rmu.h5\n",
      "(5149, 6, 6) (5149, 7) (5149, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime400_rmu.h5\n",
      "(11435, 6, 6) (11435, 7) (11435, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1500_rmu_padded.h5\n",
      "(7243, 6, 6) (7243, 7) (7243, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime2000_re.h5\n",
      "(5454, 6, 6) (5454, 7) (5454, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_singletop_re.h5\n",
      "(1134807, 6, 6) (1134807, 7) (1134807, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_singletop_rmu.h5\n",
      "(1233495, 6, 6) (1233495, 7) (1233495, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime500_rmu_padded.h5\n",
      "(11256, 6, 6) (11256, 7) (11256, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime750_rmu_padded.h5\n",
      "(13853, 6, 6) (13853, 7) (13853, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1500_rmu.h5\n",
      "(8875, 6, 6) (8875, 7) (8875, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zjets_rmu.h5\n",
      "(983017, 6, 6) (983017, 7) (983017, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime750_re.h5\n",
      "(14775, 6, 6) (14775, 7) (14775, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zjets_re.h5\n",
      "(1474788, 6, 6) (1474788, 7) (1474788, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime4000_re.h5\n",
      "(3252, 6, 6) (3252, 7) (3252, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime3000_rmu.h5\n",
      "(5531, 6, 6) (5531, 7) (5531, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime4000_rmu.h5\n",
      "(3638, 6, 6) (3638, 7) (3638, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime750_rmu.h5\n",
      "(15604, 6, 6) (15604, 7) (15604, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime400_re.h5\n",
      "(9817, 6, 6) (9817, 7) (9817, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1250_re.h5\n",
      "(10649, 6, 6) (10649, 7) (10649, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1750_rmu.h5\n",
      "(6719, 6, 6) (6719, 7) (6719, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime2500_re.h5\n",
      "(3914, 6, 6) (3914, 7) (3914, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime2000_rmu.h5\n",
      "(6210, 6, 6) (6210, 7) (6210, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime500_rmu.h5\n",
      "(12614, 6, 6) (12614, 7) (12614, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime2500_rmu.h5\n",
      "(4542, 6, 6) (4542, 7) (4542, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_vv_re.h5\n",
      "(95259, 6, 6) (95259, 7) (95259, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_vv_rmu.h5\n",
      "(79143, 6, 6) (79143, 7) (79143, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime500_re.h5\n",
      "(11545, 6, 6) (11545, 7) (11545, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_wjets_rmu.h5\n",
      "(1745078, 6, 6) (1745078, 7) (1745078, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime5000_re.h5\n",
      "(4761, 6, 6) (4761, 7) (4761, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1000_re.h5\n",
      "(19597, 6, 6) (19597, 7) (19597, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime3000_re.h5\n",
      "(4766, 6, 6) (4766, 7) (4766, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime2750_rmu.h5\n",
      "(4148, 6, 6) (4148, 7) (4148, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime2750_re.h5\n",
      "(3460, 6, 6) (3460, 7) (3460, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1500_re.h5\n",
      "(8646, 6, 6) (8646, 7) (8646, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1250_rmu.h5\n",
      "(11102, 6, 6) (11102, 7) (11102, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_zprime1000_rmu.h5\n",
      "(20219, 6, 6) (20219, 7) (20219, 20)\n",
      "./../../../../../data/hongtao/inputs_2021-02-05/variables_wjets_re.h5\n",
      "(1545084, 6, 6) (1545084, 7) (1545084, 20)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Input, concatenate, Masking, LSTM, TimeDistributed, Lambda, Reshape, Multiply, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras import regularizers \n",
    "from tensorflow.keras import initializers\n",
    "import h5py \n",
    "import os \n",
    "from clr_callback import *\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow.keras.backend as K  \n",
    "from tensorflow.keras.optimizers import * \n",
    "import glob\n",
    "import re\n",
    "import importlib \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "names = glob.glob(\"./../../../../../data/hongtao/inputs_2021-02-05/*_padded.h5\")\n",
    "def loss_fc(true, pred):\n",
    "        return K.mean(K.square(true-pred)*(1+3*K.square(K.abs(true))))\n",
    "\n",
    "names.remove('./../../../../../data/hongtao/inputs_2021-02-05/variables_tt_rmu_padded.h5')\n",
    "names.remove('./../../../../../data/hongtao/inputs_2021-02-05/variables_tt_re_padded.h5')\n",
    "\n",
    "for name in names:\n",
    "    name = re.sub('\\_padded.h5$', '', name)+'.h5'\n",
    "    name0 = os.path.basename(name)\n",
    "    name0 = re.sub('\\.h5$', '', name0)\n",
    "    dataset = h5py.File(name,'r')\n",
    "    # ['j1_pt', 'j1_eta', 'j1_phi', 'j1_x', 'j1_y', 'j1_z', 'j1_m', 'j1_e', 'j1_DL1r', 'j1_isbtag', 'j2_pt', 'j2_eta', 'j2_phi', 'j2_x', 'j2_y', 'j2_z', 'j2_m', 'j2_e', 'j2_DL1r', 'j2_isbtag', 'j3_pt', 'j3_eta', 'j3_phi', 'j3_x', 'j3_y', 'j3_z', 'j3_m', 'j3_e', 'j3_DL1r', 'j3_isbtag', 'j4_pt', 'j4_eta', 'j4_phi', 'j4_x', 'j4_y', 'j4_z', 'j4_m', 'j4_e', 'j4_DL1r', 'j4_isbtag', 'j5_pt', 'j5_eta', 'j5_phi', 'j5_x', 'j5_y', 'j5_z', 'j5_m', 'j5_e', 'j5_DL1r', 'j5_isbtag', 'j6_pt', 'j6_eta', 'j6_phi', 'j6_x', 'j6_y', 'j6_z', 'j6_m', 'j6_e', 'j6_DL1r', 'j6_isbtag', 'lep_pt', 'lep_eta', 'lep_phi', 'lep_x', 'lep_y', 'lep_z', 'lep_e', 'met_met', 'met_phi']\n",
    "    size = np.array(dataset.get('th_pt')).size\n",
    "    X_keys = ['j1_pt', 'j1_eta', 'j1_phi', 'j1_m', 'j1_DL1r', 'j2_pt', 'j2_eta', 'j2_phi', 'j2_m', 'j2_DL1r', 'j3_pt', 'j3_eta', 'j3_phi', 'j3_m', 'j3_DL1r', 'j4_pt', 'j4_eta', 'j4_phi', 'j4_m', 'j4_DL1r', 'j5_pt', 'j5_eta', 'j5_phi', 'j5_m', 'j5_DL1r', 'j6_pt', 'j6_eta', 'j6_phi', 'j6_m', 'j6_DL1r', 'lep_pt', 'lep_eta', 'lep_phi', 'met_met', 'met_phi']\n",
    "    Y_keys = ['th_pt', 'th_eta','th_phi','th_m', 'wh_pt', 'wh_eta', 'wh_phi', 'wh_m', 'tl_pt', 'tl_eta', 'tl_phi', 'tl_m', 'wl_pt', 'wl_eta', 'wl_phi', 'wl_m']\n",
    "\n",
    "    phi_keys = list(filter(lambda a: 'phi' in a, dataset.keys()))\n",
    "    eta_keys = list(filter(lambda a: 'eta' in a, dataset.keys()))\n",
    "    pt_keys =  list(filter(lambda a: 'pt' in a, dataset.keys()))\n",
    "    m_keys = list(filter(lambda a: 'm' in a, dataset.keys()))\n",
    "    DL1r_keys = list(filter(lambda a: 'DL1r' in a, dataset.keys()))\n",
    "\n",
    "    Y_length = len(Y_keys)\n",
    "    X_length = len(X_keys)\n",
    "    crop0 =  size\n",
    "    print(name)\n",
    "\n",
    "    X_maxmean = np.load('saved/X_maxmean1.npy')\n",
    "    Y_maxmean = np.load('saved/Y_maxmean1.npy')\n",
    "\n",
    "    import normalize\n",
    "    importlib.reload(normalize)\n",
    "    import shape_timesteps\n",
    "    importlib.reload(shape_timesteps)\n",
    "\n",
    "    Scaler = normalize.Scale_variables()\n",
    "    X_total, X_names = Scaler.scale_arrays(X_keys, X_maxmean)\n",
    "    Y_total, Y_names = Scaler.scale_arrays(Y_keys, Y_maxmean)\n",
    "\n",
    "    # print('Max scaling error: {}'.format(error))\n",
    "\n",
    "    # Create X and test array\n",
    "    split = int(np.floor(0.95*crop0)) \n",
    "    split = 0 \n",
    "\n",
    "    trainY, testY = Y_total[0:split,:], Y_total[split:,:]\n",
    "\n",
    "    timestep_builder = shape_timesteps.Shape_timesteps()\n",
    "\n",
    "    totalX_jets, totalX_other = timestep_builder.reshape_X(X_total, X_names, False,True)\n",
    "\n",
    "    trainX_jets, testX_jets = totalX_jets[0:split,:,:], totalX_jets[split:,:,:]\n",
    "    trainX_other, testX_other = totalX_other[0:split,:], totalX_other[split:,:]\n",
    "    print(testX_jets.shape, testX_other.shape, testY.shape)\n",
    "    \n",
    "    if testX_jets.shape[0] > 0: \n",
    "        other_bins = np.linspace(-1, 1, 40)\n",
    "        phi_bins = np.linspace(-1, 1, 40)\n",
    "        pt_bins = np.linspace(-1, 1, 40)\n",
    "        Y_bins = [phi_bins if 'phi' in name else pt_bins if 'pt' in name else other_bins for name in Y_names]\n",
    "\n",
    "        model = keras.models.load_model('12-3-clean.keras', custom_objects={'loss_fc':loss_fc})\n",
    "\n",
    "        predictions_unscaled = model.predict([testX_jets, testX_other])\n",
    "        true_unscaled = testY \n",
    "\n",
    "        total_predictions = model.predict([np.append(trainX_jets,testX_jets,axis=0), np.append(trainX_other,testX_other,axis=0)])\n",
    "        Y_total, _ = Scaler.scale_arrays(Y_keys, Y_maxmean)\n",
    "\n",
    "        predictions_origscale = Scaler.invscale_arrays(total_predictions, Y_names, Y_maxmean)[split:,:]\n",
    "        true_origscale = Scaler.invscale_arrays(Y_total, Y_names, Y_maxmean)[split:,:]\n",
    "\n",
    "        np.save('saved/13-3-2021/'+name0+'_unpadded', predictions_origscale)\n",
    "        np.save('saved/13-3-2021/'+name0+'unpadded-true', true_origscale)\n",
    "    else:\n",
    "        print('skip')\n",
    "    dataset.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Histograms of total  Y variables \n",
    "# show = False\n",
    "\n",
    "# other_bins = np.linspace(-1, 1, 40)\n",
    "# phi_bins = np.linspace(-1, 1, 40)\n",
    "# pt_bins = np.linspace(-1, 1, 40)\n",
    "# Y_bins = [phi_bins if 'phi' in name else pt_bins if 'pt' in name else other_bins for name in Y_names]\n",
    "\n",
    "# if show:\n",
    "#     plt.figure(figsize=(6,6*trainY.shape[1]))\n",
    "#     for i in range(0, trainY.shape[1]):\n",
    "#         plt.subplot(trainY.shape[1], 1, i+1)\n",
    "#         bins = Y_bins[i]\n",
    "#         plt.hist(Y_total[:,i], bins, histtype='step')\n",
    "#         plt.xlabel(Y_names[i])\n",
    "#         plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Histograms of X variables (without the mask)\n",
    "# show = False\n",
    "\n",
    "# if show:\n",
    "#     plt.figure(figsize=(6,6*X_total.shape[1]))\n",
    "#     for i in range(0, X_total.shape[1]):\n",
    "#         plt.subplot(X_total.shape[1], 1, i+1)\n",
    "#         plt.hist(X_total[:,i], 40, histtype='step')\n",
    "#         plt.xlabel(X_names[i])\n",
    "#         plt.ylabel('Frequency')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model():\n",
    "#     jet_input = Input(shape=(trainX_jets.shape[1], trainX_jets.shape[2]))\n",
    "#     Mask = Masking(-2)(jet_input)\n",
    "#     Maskshape = Reshape((trainX_jets.shape[1], trainX_jets.shape[2]))(Mask)\n",
    "#     other_input = Input(shape=(trainX_other.shape[1]))\n",
    "#     flat_jets =  Flatten()(jet_input)\n",
    "#     concat0 = concatenate([other_input, flat_jets])\n",
    "#     PreDense1 = Dense(256, activation='relu')(concat0)\n",
    "#     PreDense2 = Dense(256, activation='relu')(PreDense1)\n",
    "#     PreDense3 = Dense(trainX_jets.shape[1], activation='sigmoid')(PreDense2)\n",
    "#     Shape_Dot = Reshape((-1,1))(PreDense3)\n",
    "    \n",
    "#     TDDense11 = TimeDistributed(Dense(128, activation='relu'))(Maskshape)\n",
    "#     TDDense12 = TimeDistributed(Dense(64, activation='relu'))(TDDense11)\n",
    "#     Dot_jets = Multiply()([Shape_Dot, TDDense12])\n",
    "#     TDDense13 = TimeDistributed(Dense(128, activation='relu'))(Dot_jets)\n",
    "#     TDDense14= TimeDistributed(Dense(128, activation='relu'))(TDDense13)\n",
    "#     flat_right = Flatten()(TDDense14)\n",
    "    \n",
    "#     Dense21 = Dense(128, activation='relu')(other_input)\n",
    "#     Dense22 = Dense(128, activation='relu')(Dense21)\n",
    "#     flat_other = Flatten()(Dense22)\n",
    "    \n",
    "#     concat = concatenate([flat_other, flat_right])\n",
    "    \n",
    "#     ldense1 = Dense(256, activation='relu')(concat)\n",
    "#     ldense2 = Dense(128, activation='relu')(ldense1)\n",
    "#     loutput = Dense(len(Y_names)//2)(ldense2)\n",
    "    \n",
    "#     hconcat = concatenate([loutput, concat])\n",
    "#     hdense1 = Dense(256, activation='relu')(hconcat)\n",
    "#     hdense2 = Dense(128, activation='relu')(hdense1)\n",
    "#     houtput = Dense(len(Y_names)//2)(hdense2)\n",
    "    \n",
    "#     output = concatenate([houtput, loutput])\n",
    "    \n",
    "#     model = keras.models.Model(inputs=[jet_input, other_input], outputs=output)\n",
    "    \n",
    "#     def loss_fc(true, pred):\n",
    "#         return K.mean(K.square(true-pred)*(1+3*K.square(K.abs(true))))\n",
    "#     # lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-3, decay_steps=5000,decay_rate=0.6)\n",
    "#     lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(initial_learning_rate=1e-3, decay_steps=10000,end_learning_rate=5e-5,power=0.25)\n",
    "#     optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "#     model.compile(loss='mae', optimizer= optimizer, metrics=['mse'])\n",
    "    \n",
    "#     return model \n",
    "\n",
    "# def loss_fc(true, pred):\n",
    "#         return K.mean(K.square(true-pred)*(1+3*K.square(K.abs(true))))\n",
    "    \n",
    "# model = keras.models.load_model('12-3-clean.keras', custom_objects={'loss_fc':loss_fc})\n",
    "# # model = build_model()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_unscaled = model.predict([testX_jets, testX_other])\n",
    "# true_unscaled = testY \n",
    "\n",
    "# total_predictions = model.predict([np.append(trainX_jets,testX_jets,axis=0), np.append(trainX_other,testX_other,axis=0)])\n",
    "# Y_total, _ = Scaler.scale_arrays(Y_keys, Y_maxmean)\n",
    "\n",
    "# predictions_origscale = Scaler.invscale_arrays(total_predictions, Y_names, Y_maxmean)[split:,:]\n",
    "# true_origscale = Scaler.invscale_arrays(Y_total, Y_names, Y_maxmean)[split:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('saved/13-3-2021/'+name0, predictions_origscale)\n",
    "# np.save('saved/13-3-2021/'+name0+'-true', true_origscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training scale plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import analysis\n",
    "\n",
    "# Analysis = analysis.Analysis \n",
    "# Analysis.display_errors(predictions_unscaled, true_unscaled, Y_names, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Analysis.display_errors(predictions_origscale, true_origscale, Y_keys, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis.predictions_vs_sample(predictions_unscaled, true_unscaled, Y_names, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis.variable_histogram(predictions_unscaled, true_unscaled, Y_names, False, Y_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis.difference_histogram(predictions_unscaled, true_unscaled, Y_names, False, Y_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analysis.predicted_vs_true(predictions_unscaled, true_unscaled, Y_names, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    " # Original scale plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Analysis.display_errors(predictions_origscale, true_origscale, Y_keys, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis.predictions_vs_sample(predictions_origscale, true_origscale, Y_keys, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Analysis.variable_histogram(predictions_origscale, true_origscale, Y_keys, True, [None for name in Y_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analysis.predicted_vs_true(predictions_origscale, true_origscale, Y_keys, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('Jet_Reweight_lr_decay_ex-mae.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import observables \n",
    "# import importlib\n",
    "# importlib.reload(observables)\n",
    "# truths = observables.fill_observables(true_origscale, True, Y_keys)\n",
    "# preds = observables.fill_observables(predictions_origscale, False, Y_keys)\n",
    "\n",
    "# # top_dphi=np.abs(th_phi-tl_phi)\n",
    "# plt.figure(figsize=(12,6))\n",
    "# observables.plot_hist(truths['top_dphi'], preds['top_dphi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # top_m0= th_m**2-th_p**2 + tl_m**2-tl_p**2\n",
    "# plt.figure(figsize=(12,6))\n",
    "# observables.plot_hist(truths['top_m0'],preds['top_m0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # eta_cm=0.5*(th_eta-tl_eta), eta_boost=0.5*(th_eta+tl_eta)\n",
    "# plt.figure(figsize=(12,12))\n",
    "# plt.subplot(211)\n",
    "# observables.plot_hist(truths['eta_cm'], preds['eta_cm'])\n",
    "# plt.subplot(212)\n",
    "# observables.plot_hist(truths['eta_boost'], preds['eta_boost'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # th_Pout=dot(th_P, cross(tl_P,ez)/norm(tl_P,ez)), tl_Pout=dot(tl_P, cross(th_P,ez)/norm(th_P,ez))\n",
    "# plt.figure(figsize=(12,12))\n",
    "# plt.subplot(211)\n",
    "# observables.plot_hist(truths['th_Pout'], preds['th_Pout'])\n",
    "# plt.subplot(212)\n",
    "# observables.plot_hist(truths['tl_Pout'], preds['tl_Pout'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pt_tot = th_pt+tl_pt\n",
    "# plt.figure(figsize=(12,6))\n",
    "# observables.plot_hist(truths['pt_tot'],preds['pt_tot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
